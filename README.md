## Induced Set Attention Block (ISAB) - Pytorch

A concise implementation of (Induced) Set Attention Block, from the Set Transformers paper.

## Citations

```bibtex
@misc{lee2019set,
      title={Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks}, 
      author={Juho Lee and Yoonho Lee and Jungtaek Kim and Adam R. Kosiorek and Seungjin Choi and Yee Whye Teh},
      year={2019},
      eprint={1810.00825},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
```
